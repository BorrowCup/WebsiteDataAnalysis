{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cafe Sale Scan Rates Analysis\n",
    "\n",
    "This notebook aims to analyse the Sale scan rates at different cafes post 22nd Jan 2020, comparing total scans each day with number of used cups at each cafe from the manual data in Google Spreadsheet.\n",
    "\n",
    "Author: Arihant Jain\n",
    "\n",
    "Date: 12th October 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Data\n",
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-68fe276bf976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_datetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmelt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdotenv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "from requests import get\n",
    "from pandas import DataFrame, to_datetime, read_csv, merge, melt\n",
    "from time import time\n",
    "from plotly.graph_objects import Figure, Scatter\n",
    "from plotly.express import box, colors\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import json, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set how many days old the data can be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetchSaleData = True\n",
    "\n",
    "# for 1 day\n",
    "lastUpdatedInDays = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if data is present locally and if it can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current time\n",
    "currentTime = time()\n",
    "timeToCheckAgainst = datetime.fromtimestamp(currentTime - lastUpdatedInDays*24*60*60)\n",
    "\n",
    "if not os.path.exists('../data files'):\n",
    "    os.makedirs('../data files')\n",
    "\n",
    "print('Checking for sale data...')\n",
    "if os.path.exists(\"../data files/rawSaleData.json\"):\n",
    "    saleDataTime = datetime.fromtimestamp(os.path.getmtime('../data files/rawSaleData.json'))\n",
    "    print('Found sale data from:', saleDataTime.strftime('%c'))\n",
    "    \n",
    "    # if older than 'lastUpdatedInDays' days, fetch again\n",
    "    if saleDataTime <= timeToCheckAgainst:\n",
    "        print('Locally saved data is older than {} hours!'.format(lastUpdatedInDays*24))\n",
    "        print('Have to fetch again...')\n",
    "        fetchSaleData = True\n",
    "    else:\n",
    "        print('Will be using this locally saved data...')\n",
    "        fetchSaleData = False\n",
    "else:\n",
    "    print('No local data found!')\n",
    "    print('Have to fetch again...')\n",
    "    fetchSaleData = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get URL from .env if in case we fetch from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "domain = os.getenv(\"URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fetchSaleData:\n",
    "    print('Getting Sale data... Please wait!')\n",
    "    startTime = time()\n",
    "\n",
    "    # get sale data\n",
    "    response = get('https://' + domain + 'sale')\n",
    "    saleData = response.json()\n",
    "\n",
    "    print('Took', round(time() - startTime, 2), 'seconds to get Sale data.')\n",
    "    \n",
    "    # save locally for later reuse\n",
    "    with open('../data files/rawSaleData.json', 'w') as fp:\n",
    "        json.dump(saleData, fp, indent=4)\n",
    "else:\n",
    "    # use locally saved data\n",
    "    with open('../data files/rawSaleData.json', 'r') as fp:\n",
    "        saleData = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep\n",
    "#### Working with Sale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataframe\n",
    "saleDF = DataFrame.from_dict(saleData, orient='columns')\n",
    "\n",
    "# dropping columns\n",
    "saleDF = saleDF.drop(['cup_id', 'id', 'scanned_at', 'return_id', 'scanned_at_melbourne_date_time', 'scanned_at_melbourne_time'], axis=1)\n",
    "\n",
    "# renaming columns\n",
    "saleDF = saleDF.rename(columns={\"scanned_at_melbourne_date\": \"date\"})\n",
    "\n",
    "# converting date column to datetime64 datatype\n",
    "saleDF['date'] = to_datetime(saleDF['date'], dayfirst=True)\n",
    "\n",
    "# get data post 22nd Jan 2020\n",
    "saleDF = saleDF[saleDF['date'] >= '2020/01/22']\n",
    "\n",
    "# get weeks from date\n",
    "saleDF['week'] = saleDF['date'].dt.isocalendar().week\n",
    "\n",
    "# drop date\n",
    "saleDF = saleDF.drop('date', axis=1)\n",
    "\n",
    "saleDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping by cafes and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedOnlineSalesDF = saleDF.groupby(['cafe_id','week']).size().reset_index(name='online_count')\n",
    "groupedOnlineSalesDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from Google Spreadsheet\n",
    "\n",
    "#### Prepare link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spreadsheet link from .env file\n",
    "spreadsheetLink = os.getenv(\"Google_Spreadsheet_URL\")\n",
    "\n",
    "# this is the sheet name\n",
    "sheetName = 'Responses'\n",
    "\n",
    "# complete url\n",
    "url = spreadsheetLink + 'gviz/tq?tqx=out:csv&sheet=' + sheetName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheetDF = read_csv(url)\n",
    "\n",
    "# get columns to be deleted programatically\n",
    "cols = []\n",
    "for col in sheetDF.columns:\n",
    "    if 'have' in col.lower() or 'notes' in col.lower() or 'checked' in col.lower() or 'unnamed' in col.lower():\n",
    "        cols.append(col)\n",
    "\n",
    "# make list of columns to be deleted\n",
    "deleteCols = cols + ['Timestamp', 'Name of BorrowCup assistant']\n",
    "sheetDF = sheetDF.drop(deleteCols, axis=1)\n",
    "sheetDF = sheetDF.rename(columns={'Date Today': 'Date'})\n",
    "sheetDF['Date'] = to_datetime(sheetDF['Date'], yearfirst=True)\n",
    "sheetDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with manual return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "sheetsDF = sheetDF.drop(['Week Number', 'Year', 'Washed'], axis=1)\n",
    "\n",
    "sheetsDF = sheetsDF[sheetsDF['Date'] >= '2020/01/22']\n",
    "\n",
    "# rename columns\n",
    "renamed = {\n",
    "    'Nesso Café Used': '101',\n",
    "    'Cafelito Used': '102',\n",
    "    'Taste Baguette Used': '103',\n",
    "    'Church of Secular Coffee Used': '104',\n",
    "    'Swifts Used': '105',\n",
    "    'Wholefoods Used': '106',\n",
    "    'Supernatural Eatery Used': '107',\n",
    "    'Script Used': '108',\n",
    "    'Cinque Lire Café Used': '109'\n",
    "}\n",
    "sheetsDF = sheetsDF.rename(columns=renamed)\n",
    "\n",
    "sheetsDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt the dataframe so that cafe columns become one column with cafe ids as values\n",
    "# See https://pandas.pydata.org/docs/reference/api/pandas.melt.html\n",
    "sheetsDF = melt(sheetsDF, id_vars = sheetsDF.columns[0], value_vars = sheetsDF.columns[1:], var_name='cafe_id', value_name='manual_count')\n",
    "\n",
    "# get week numbers from Date\n",
    "sheetsDF['week'] = sheetsDF['Date'].dt.isocalendar().week\n",
    "\n",
    "# drop date column\n",
    "sheetsDF = sheetsDF.drop(['Date'], axis=1)\n",
    "\n",
    "# rearrange columns\n",
    "sheetsDF = sheetsDF[['cafe_id', 'week', 'manual_count']]\n",
    "\n",
    "# change cafe_id column type from object to int64\n",
    "sheetsDF[\"cafe_id\"] = sheetsDF[\"cafe_id\"].astype(str).astype(int)\n",
    "\n",
    "sheetsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by cafe id and week number\n",
    "groupedManualSalesDF = sheetsDF.groupby(['cafe_id', 'week']).sum().reset_index()\n",
    "\n",
    "groupedManualSalesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging online (left) and manual (right) data with an outer join\n",
    "mergedDF = merge(left=groupedOnlineSalesDF, right=groupedManualSalesDF, how='outer', on=['cafe_id', 'week'], indicator='present', validate='1:1')\n",
    "\n",
    "# sort by cafe_id, week\n",
    "mergedDF = mergedDF.sort_values(by=['cafe_id', 'week'], ignore_index=True)\n",
    "mergedDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking if we have complete missing whole week records in any one data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDF.present.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`right_only` suggests that, for some cafe-week pairs, online collected data is missing.\n",
    "\n",
    "#### Let's investigate what are those cafe-week pairs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDF[mergedDF['present'] == 'right_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for most cafe-week pairs, the sales have been zero as the manual sales count is zero - for which the online sales count would be obviously non-existent (thus NaN). Furthermore, it can be seen that there are only 2 cafes in 15 of the total 17 intances where manual sales count is zero. These are 102 (Cafelito) and 106 (Wholefoods). This is understandable as these cafes were mostly closed during the small period BorrowCup operated in 2020. Wholefoods was never open and Cafelito may have opened\n",
    "for a day or two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby converted NaNs to zero on summation\n",
    "\n",
    "We can see from the distinct values of the manual count below that, upon grouping and summation, for those cafe-week pairs where all manual sales count were only NaNs, those cafe-week pairs were assigned Zero in the output dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedManualSalesDF.manual_count.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing such rows where cafe-week pair manual sales count is zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check whether all zero manual counts are among the 17 instances seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDF[mergedDF['manual_count'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep. It is easier to see that the instances are the same when you look that they are all `right_only` instances. They are 15 in total.\n",
    "\n",
    "So we can remove them easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDF = mergedDF[mergedDF['manual_count'] != 0]\n",
    "\n",
    "mergedDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we know that there were 17 instances where no online sales was recorded, out of which 15 were removed in the previous step. We now have 2 instances (rows) where there is `right_only` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDF[mergedDF['present'] == 'right_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we saw that there are 2 NaNs here.\n",
    "\n",
    "Let's see if we have more NaNs anywhere else in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDF[mergedDF.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No. We don't have any other NaNs anywhere else. \n",
    "\n",
    "Since we know that online count NaNs implies that there was no online data collected for that week. We can set them to Zero for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN with zeroes\n",
    "mergedDF['online_count'] = mergedDF['online_count'].fillna(0)\n",
    "\n",
    "mergedDF.loc[mergedDF['present'] == 'right_only', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get scan percentages (or rates)\n",
    "\n",
    "Formula:\n",
    "\n",
    "$$percentage = \\frac{online\\,count}{manual\\,count}\\times 100$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDF['percent'] = round(mergedDF['online_count']/mergedDF['manual_count']*100)\n",
    "\n",
    "mergedDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have scan rates, let's join this data with cafe names data to read and understand quickly and clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading cafes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../data files/cafes.csv\"):\n",
    "    print('Existing cafes file not found. Run the GetCafesData.ipynb notebook.')\n",
    "else:\n",
    "    # read the csv file\n",
    "    cafesDF = read_csv('../data files/cafes.csv')\n",
    "    \n",
    "    # drop columns\n",
    "    cafesDF = cafesDF.drop(['name', 'latitude', 'longitude'], axis=1)\n",
    "cafesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining cafes data with sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join\n",
    "mergedDF = merge(mergedDF, cafesDF, left_on = 'cafe_id', right_on = 'id')\n",
    "\n",
    "# drop columns\n",
    "mergedDF = mergedDF.drop(['present', 'id'], axis=1)\n",
    "\n",
    "# rearrange columns\n",
    "mergedDF = mergedDF[['cafe_name', 'cafe_id', 'week', 'online_count', 'manual_count', 'percent']]\n",
    "\n",
    "mergedDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking how the data looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDF['percent'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check scan rates spread for each cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = box(mergedDF, x=\"percent\", y=\"cafe_name\", color=\"cafe_name\")\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating line chart for scan rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces\n",
    "fig = Figure()\n",
    "for cafe_id in mergedDF['cafe_id'].unique():\n",
    "    fig.add_trace(Scatter(x=mergedDF['week'], y=mergedDF.loc[mergedDF['cafe_id'] == cafe_id, 'percent'],\n",
    "                        mode='lines+markers',\n",
    "                        name=mergedDF.loc[mergedDF['cafe_id'] == cafe_id, 'cafe_name'].unique()[0],\n",
    "                        line_shape='spline'))\n",
    "\n",
    "# Edit the layout\n",
    "fig.update_layout(title='Scan rates per cafe per week line chart',\n",
    "                   xaxis_title='Week',\n",
    "                   yaxis_title='Percentage')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces\n",
    "fig = Figure()\n",
    "cafe_ids = mergedDF['cafe_id'].unique()\n",
    "colorDict = dict(zip(cafe_ids, colors.qualitative.Plotly))\n",
    "for cafe_id in cafe_ids:\n",
    "    \n",
    "    x = mergedDF.loc[mergedDF['cafe_id'] == cafe_id, 'week']\n",
    "    y = mergedDF.loc[mergedDF['cafe_id'] == cafe_id, 'percent']\n",
    "    z = np.polyfit(x, y, 2)\n",
    "    p = np.poly1d(z)\n",
    "    mergedDF.loc[mergedDF['cafe_id'] == cafe_id,'regressionPercentage'] = p(x)\n",
    "    \n",
    "    fig.add_trace(Scatter(x=x, y=y,\n",
    "                          mode='markers',\n",
    "                          name=mergedDF.loc[mergedDF['cafe_id'] == cafe_id, 'cafe_name'].unique()[0],\n",
    "                          marker_color=colorDict[cafe_id],\n",
    "                          showlegend=False,\n",
    "                          marker={'size':8},\n",
    "                          legendgroup=str(cafe_id)\n",
    "                         ))\n",
    "\n",
    "    fig.add_trace(Scatter(x=x, y=p(x),\n",
    "                          mode='lines',\n",
    "                          name=mergedDF.loc[mergedDF['cafe_id'] == cafe_id, 'cafe_name'].unique()[0],\n",
    "                          line_color=colorDict[cafe_id],\n",
    "                          legendgroup=str(cafe_id)\n",
    "                         ))\n",
    "\n",
    "# Edit the layout\n",
    "fig.update_layout(title='Scan rates per cafe per week line chart',\n",
    "                  xaxis_title='Week',\n",
    "                  yaxis_title='Percentage',\n",
    "                  legend_title_text='Cafes')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving scan rates data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDF.to_csv('../data files/saleScanRates.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
